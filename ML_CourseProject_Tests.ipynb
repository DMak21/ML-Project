{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAD19YNz2Ee3"
   },
   "source": [
    "You have 6 cells in this notebook to fill. Follow the instructions in the Notebook very carefully and **do the exact thing** we have asked you to.\n",
    "\n",
    "You will be using your package and making your api calls do train and predict for the dataset we give for each algorithm that you coded up.\n",
    "\n",
    "The external dataset used in cells 4-6 has to be downloaded from here. The data is already in form on X_train, y_train And X_test for you. Do\n",
    "not do your splits.\n",
    "\n",
    "Link for dataset\n",
    "https://drive.google.com/file/d/1QUPvOCGSkOZjNneFeUQ_cgu1dOMgJE3V/view?usp=sharing\n",
    "\n",
    "\n",
    "Submit this notebook filled by tomorrow Midnight, ie, 25th  April, Midnight, in this folder\n",
    "https://drive.google.com/drive/folders/18jrjzCpibUqs8YUoYs6FXvBZqWlY_eix?usp=sharing\n",
    "\n",
    "The notebook name should be your team number which you used during code submission.\n",
    "We will run the 6 cells and if your cell runs, you will get marks for it, else you won't. So, code carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCyKV4E32rU8"
   },
   "source": [
    "1. Naive Bayes\n",
    "\n",
    "Hyperparameters: \n",
    "type=multinomial, priors=[0.5, 0.5]\n",
    "\n",
    "**Train 1**\n",
    "X = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]]), y=np.array([1, 0, 0, 0]) \n",
    "**Test 1**\n",
    "X=  np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "**Train 2**\n",
    "X = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]]), y=np.array([0, 1, 0, 1])\n",
    "**Test 2**\n",
    "X = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCYSG3K31_wy"
   },
   "outputs": [],
   "source": [
    "# INSERT NAIVE BAYES TRAIN AND TEST CODE HERE\n",
    "from NaiveBayes.NaiveBayes import *\n",
    "\n",
    "X_train1 = pd.DataFrame(np.array([[1., 1.,1], [1, -1,0], [-1, -1,0], [-1, 1.,0]]))\n",
    "X_test1 = pd.DataFrame(np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]]))\n",
    "\n",
    "X_train2 = pd.DataFrame(np.array([[1., 1.,0], [1, -1,1], [-1, -1,0], [-1, 1.,1]]))\n",
    "X_test2 = pd.DataFrame(np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]]))\n",
    "\n",
    "p = pd.DataFrame([np.array([0.5, 0.5])],columns=['Row1','Row2'])\n",
    "NBC = NaiveBayes('Multinomial',p)\n",
    "\n",
    "NBC.fit(X_train1)\n",
    "y_pred1 = NBC.predict(X_test1)\n",
    "\n",
    "NBC.fit(X_train2)\n",
    "y_pred2 = NBC.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F4eVl9IN3TVu"
   },
   "source": [
    "2. Decision Tree\n",
    "\n",
    "Hyperparameters: \n",
    "type=max_depth = 2, Split_node_criterion = ”gini”\n",
    "\n",
    "**Train 1**\n",
    "X = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]]), y=np.array([1, 0, 0, 0]) \n",
    "**Test 1**\n",
    "X=  np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "**Train 2**\n",
    "X = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]]), y=np.array([0, 1, 0, 1])\n",
    "**Test 2**\n",
    "X = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfdBoHvX3Rce"
   },
   "outputs": [],
   "source": [
    "# INSERT Decision Tree TRAIN AND TEST CODE HERE\n",
    "from decisiontree import *\n",
    "\n",
    "X_train1 = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]])\n",
    "y_train1 = np.array([1, 0, 0, 0])\n",
    "X_test1  = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "dt1 = DecisionTree(max_depth=2,split_node_criterion='gini')\n",
    "dt1.fit(X_train1,y_train1)\n",
    "pred1 = dt1.predict(X_test1)\n",
    "\n",
    "X_train2 = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]])\n",
    "y_train2 = np.array([0, 1, 0, 1])\n",
    "X_test2  = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "dt2 = DecisionTree(max_depth=2,split_node_criterion ='gini')\n",
    "dt2.fit(X_train2,y_train2)\n",
    "pred2 = dt2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJTAxjzO3yXz"
   },
   "source": [
    "3. Logistic Regression\n",
    "\n",
    "Hyperparameters: \n",
    "type = learning_rate=0.01, num_steps =100\n",
    "\n",
    "**Train 1**\n",
    "X = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]]), y=np.array([1, 0, 0, 0]) \n",
    "**Test 1**\n",
    "X=  np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "**Train 2**\n",
    "X = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]]), y=np.array([0, 1, 0, 1])\n",
    "**Test 2**\n",
    "X = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UGKAna783wiS"
   },
   "outputs": [],
   "source": [
    "# INSERT Logistic Regression TRAIN AND TEST CODE HERE\n",
    "\n",
    "from LogisticRegression.LogisticRegression import *\n",
    "\n",
    "X_train = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]])\n",
    "y_train = np.array([1, 0, 0, 0])\n",
    "X_test = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "clf1 = LogisticRegression(learning_rate=0.01, num_steps =100)\n",
    "clf1.train(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "\n",
    "X_train = np.array([[1., 1.], [1, -1], [-1, -1], [-1, 1.]])\n",
    "y_train = np.array([0, 1, 0, 1])\n",
    "X_test = np.array([[1., 1.], [1, -0.5], [-0.5, -1], [0.5, 0.5]])\n",
    "\n",
    "clf2 = LogisticRegression(learning_rate=0.01, num_steps =100)\n",
    "clf2.train(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8Cvhbs45wXG"
   },
   "source": [
    "4. Random Forest\n",
    "\n",
    "Hyperparameters : n_trees=100, max_depth=5,split_val_metric=median,split_node_criterion=entropy, max_features=sqrt, bootstrap=True, n_cores=2\n",
    "\n",
    "**Train**\n",
    "Complete X_train and y_train dataset attached. Train on full data. Do not do any internal cross validation.\n",
    "\n",
    "**Test**\n",
    "X_test attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwKIh93z5vTz"
   },
   "outputs": [],
   "source": [
    "# Insert Random Forest Train and Test Code here\n",
    "from RandomForest.RandomForest import RandomForest\n",
    "\n",
    "X_train = pd.read_csv('./data_eval/X_Train')\n",
    "y_train = pd.read_csv('./data_eval/y_Train')\n",
    "X_test = pd.read_csv('./data_eval/X_Test')\n",
    "\n",
    "rf = RandomForest(n_trees=100,max_depth=5,split_node_criterion='entropy',split_val_metric='median',bootstrap=True)\n",
    "rf.fit(X_train,y_train)\n",
    "pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ts7D3kLA6kKq"
   },
   "source": [
    "5. AdaBoost\n",
    "\n",
    "Hyperparameters : n_trees=100, learning_rate=0.01\n",
    "\n",
    "**Train**\n",
    "Complete X_train and y_train dataset attached. Train on full data. Do not do any internal cross validation.\n",
    "\n",
    "**Test**\n",
    "X_test attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zEITMZCP6gua"
   },
   "outputs": [],
   "source": [
    "# Insert AdaBoost Train and Test Code here\n",
    "from AdaBoost.Adaboost import *\n",
    "\n",
    "x_train = pd.read_csv('X_train')\n",
    "y_train = pd.read_csv('Y_train')\n",
    "x_test = pd.read_csv('X_test')\n",
    "\n",
    "ADB = Adaboost(100)\n",
    "ADB.fit(x_train, y_train)\n",
    "y_pred = ADB.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbwYWYyK6poh"
   },
   "source": [
    "6. Stacking\n",
    "\n",
    "Run stacking for the following three specifications one by one.\n",
    "\n",
    "Stacking(Logistic Regression)\n",
    "\n",
    "Stacking(Decision Tree, Decision  Tree)\n",
    "\n",
    "Stacking(Decision Tree, Logistic Regression, Logistic Regression, Naive Bayes=(“Gaussian”))\n",
    "\n",
    "\n",
    "\n",
    "**Train**\n",
    "Complete X_train and y_train dataset attached. Train on full data. Do not do any internal cross validation.\n",
    "\n",
    "**Test**\n",
    "X_test attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uxclHA486nMx"
   },
   "outputs": [],
   "source": [
    "# Insert Stacking Train and Test Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dRbOz4qJ7MfG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_CourseProject_Tests.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
